---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a 4th year undergraduate student of Dept. of Computer Science and Technology of Tsinghua University, Beijing, PRC. I am also an incomming Ph.D Student of Prof. [Minlie Huang](https://coai.cs.tsinghua.edu.cn/hml) @ [Conversational AI Group](https://coai.cs.tsinghua.edu.cn/) starting from 2025 Fall. I'm now a research intern at A*STAR's Centre for Frontier AI Research (CFAR), under the supervision of Prof. [Ong Yew-Soon](https://scholar.google.com/citations?user=h9oWOsEAAAAJ&hl=en). My research interests lie in LLM safety and alignment, and I‚Äôm recently working on the mechanism of jailbreak attack and defense of large language models, and the safety issues of Reasoning-based LLMs.

News
======

- üéâ After months of hard work and collaboration, http://CAMEL-AI.org just release its new project Loongüêâ. I'm delighted to be an contributor in it, mainly leading the safety and security domain team. I believe verifiable synthesis for complex questions will be an highly important issue for future LLM development. Here is our project [link](https://github.com/camel-ai/loong).

- üéâ AISafetyLab github [repo](https://github.com/thu-coai/AISafetyLab) released, please give us a star QWQ.

Publications
======

Conference Papers
------
- Zhang, Z.\*, **Yang, J.\***, Ke, P., Mi, F., Wang, H., & Huang, M. (2023). [Defending large language models against jailbreaking attacks through goal prioritization](https://arxiv.org/abs/2311.09096). **ACL 2024 (Long Paper)**.

Preprints
------
- **Yang, J.\***, Zhang, Z.\*, Cui, S., Wang, H., & Huang, M. (2025). [Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints](https://arxiv.org/abs/2503.01865).
- Zhang, Z.\*, Lei, L.\*, **Yang, J.\***, ... , & Huang, M. (2025). [AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement](https://arxiv.org/abs/2502.16776).
- Zhang, Z.\*, **Yang, J.\***, Ke, P., Cui, S., Zheng, C., Wang, H., & Huang, M. (2024). [Safe unlearning: A surprisingly effective and generalizable solution to defend against jailbreak attacks](https://arxiv.org/abs/2407.02855).
- Zhang, Z., Cui, S., Lu, Y., Zhou, J., **Yang, J**., Wang, H., & Huang, M. (2024). [Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org/abs/2412.14470).
- Jia, X., ... , **Yang, J.**, ... , & Zhao, Z. (2024). [Global Challenge for Safe and Secure LLMs Track 1](https://arxiv.org/pdf/2411.14502). (I was in charge of technique report of Team ModelCrackers: **Junxiao Yang\***, Zhexin Zhang\*, Leqi Lei, Renmiao Chen, Yida Lu, and Shiyao Cui, CoAI Group)

Foundation
======
I'm in charge of the following Fund.
- **Beijing Natural Science Foundation** ("Initiation Research" Program)

Teaching
======
I was a TA for the following undergraduate courses:
- **Artificial Neural Network** (2024 Fall)
- **Linear Algebra** (2024 Fall)

Honors and Awards
======
- 3rd Prize Winner of the Global Challenge for Safe and Secure LLMs (Track 1)
- Academic Excellence in Research Award of Tsinghua University, 2023.09-2024.09
- Meritorious Winner of Mathematical Contest In Modeling Certificate of Achievement, 2023
- Comprehensive Scholarship of Tsinghua University, 2022.09-2023.09
- Comprehensive Scholarship of Tsinghua University, 2021.09-2022.09

Educations
======
- 2021.09-now, Tsinghua University, Beijing, China. Undergraduate Student.
- 2018.09-2021.06, Urumqi No.1 Senior High School, Xinjiang, China. High school Student.
