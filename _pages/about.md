---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a 4th year undergraduate student of Dept. of Computer Science and Technology of Tsinghua University, Beijing, PRC. I am also an incomming Ph.D Student of Prof. [Minlie Huang](https://coai.cs.tsinghua.edu.cn/hml) @ [Conversational AI Group](https://coai.cs.tsinghua.edu.cn/) starting from 2025 Fall. I'm now a research intern at A*STAR's Centre for Frontier AI Research (CFAR), under the supervision of Prof. [Yew-Soon Ong](https://scholar.google.com/citations?user=h9oWOsEAAAAJ&hl=en). My research interests lie in LLM safety and trustworthy, and Iâ€™m recently working on the mechanism of jailbreaking attack & defense, hallucination and knowledge boundary of LRMs.

News
======

- ðŸŽ‰ Our Paper `Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints` is accepted by ACL 2025 Main! Please refer to our [code](https://github.com/thu-coai/TransferAttack) and [paper](https://arxiv.org/abs/2503.01865) for more details.

- ðŸŽ‰ Our Paper `BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs` is released.

Publications
======

Conference Papers
------
- **Yang, J.\***, Zhang, Z.\*, Cui, S., Wang, H., & Huang, M. (2025). Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints. **ACL 2025 (Long Paper)**. [link](https://arxiv.org/abs/2503.01865)
- Zhang, Z.\*, **Yang, J.\***, Ke, P., Mi, F., Wang, H., & Huang, M. (2023). Defending large language models against jailbreaking attacks through goal prioritization. **ACL 2024 (Long Paper)**. [link](https://arxiv.org/abs/2311.09096)

Preprints
------
- **Yang, J.**, Tu, J., Liu, H., Wang, X., Zheng, C., Zhang, Z., ... & Huang, M. (2025). BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs. [link](https://arxiv.org/abs/2505.13529)
- Zhang, Z.\*, Lei, L.\*, **Yang, J.\***, ... , & Huang, M. (2025). AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement. [link](https://arxiv.org/abs/2502.16776)
- Zhang, Z.\*, **Yang, J.\***, Ke, P., Cui, S., Zheng, C., Wang, H., & Huang, M. (2024). Safe unlearning: A surprisingly effective and generalizable solution to defend against jailbreak attacks. [link](https://arxiv.org/abs/2407.02855)
- Zhang, Z., Cui, S., Lu, Y., Zhou, J., **Yang, J**., Wang, H., & Huang, M. (2024). Agent-SafetyBench: Evaluating the Safety of LLM Agents. [link](https://arxiv.org/abs/2412.14470).
- Jia, X., ... , **Yang, J.**, ... , & Zhao, Z. (2024). Global Challenge for Safe and Secure LLMs Track 1. [link](https://arxiv.org/pdf/2411.14502)

Resources:
======
- AISafetyLab: a comprehensive framework for AI safety evaluation and improvement. [code](https://github.com/thu-coai/AISafetyLab) [paper](https://arxiv.org/abs/2502.16776)

Teaching
======
I was a TA for the following undergraduate courses:
- Artificial Neural Network (2024 Fall)
- Linear Algebra (2024 Fall)

Honors and Awards
======
- Excellent Graduate, Tsinghua University, 2025
- 3rd Prize Winner of the Global Challenge for Safe and Secure LLMs (Track 1)
- Academic Excellence in Research Award of Tsinghua University, 2023.09-2024.09
- Meritorious Winner of Mathematical Contest In Modeling Certificate of Achievement, 2023
- Comprehensive Scholarship of Tsinghua University, 2022.09-2023.09
- Comprehensive Scholarship of Tsinghua University, 2021.09-2022.09

Educations
======
- 2021.09-now, Tsinghua University, Beijing, China. Undergraduate Student.
- 2018.09-2021.06, Urumqi No.1 Senior High School, Xinjiang, China. High school Student.
